{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRM0iygYQB0H",
        "outputId": "c9826d29-837b-475a-e64b-8124ae6fc44c"
      },
      "id": "WRM0iygYQB0H",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.4.9-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.13.0.90)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.4.9-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.4.9 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"uU88pI1VHT5j5ddemy3t\")\n",
        "project = rf.workspace(\"ramzi-guyzk\").project(\"uang-rupiah-li6sa\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAuLVOwEQEH_",
        "outputId": "e2593bad-5d04-4236-8ec2-6a01211a2adc"
      },
      "id": "zAuLVOwEQEH_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.13-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2026.1.4)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.5-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.61.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.3.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
            "Downloading roboflow-1.2.13-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.5-cp312-cp312-manylinux_2_28_x86_64.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.13.0.90\n",
            "    Uninstalling opencv-python-headless-4.13.0.90:\n",
            "      Successfully uninstalled opencv-python-headless-4.13.0.90\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.2.0 pillow-avif-plugin-1.5.5 roboflow-1.2.13\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Uang-Rupiah-2 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1742891/1742891 [00:23<00:00, 74978.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Uang-Rupiah-2 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3116/3116 [00:11<00:00, 271.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e27dd71-2b43-48bf-9f05-eba66c1afe50",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e27dd71-2b43-48bf-9f05-eba66c1afe50",
        "outputId": "2256d820-9dd3-4863-ed0b-7d66e2a44c62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 75.4MB/s 0.1s\n",
            "Ultralytics 8.4.9 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=Uang-Rupiah-2/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 23.4MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752677  ultralytics.nn.modules.head.Detect           [7, 16, None, [64, 128, 256]] \n",
            "Model summary: 130 layers, 3,012,213 parameters, 3,012,197 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 100.6MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3482.8Â±619.5 MB/s, size: 1153.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Uang-Rupiah-2/train/labels... 1139 images, 1 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1139/1139 2.5Kit/s 0.5s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Uang-Rupiah-2/train/labels.cache\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 44, len(boxes) = 1138. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1548.9Â±1680.3 MB/s, size: 1090.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Uang-Rupiah-2/valid/labels... 271 images, 2 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 271/271 2.0Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Uang-Rupiah-2/valid/labels.cache\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 10, len(boxes) = 269. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to /content/runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      2.03G     0.8934      3.071       1.27          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.4s/it 1:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.1s/it 9.7s\n",
            "                   all        271        269      0.606      0.308      0.355      0.256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      2.52G      0.829      1.988      1.177          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.1s/it 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.0it/s 4.5s\n",
            "                   all        271        269      0.423      0.668      0.555      0.415\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      2.54G     0.8111      1.566      1.156          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.7s\n",
            "                   all        271        269      0.686      0.801      0.825      0.643\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      2.56G     0.8207      1.313      1.153         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.1it/s 4.2s\n",
            "                   all        271        269      0.817      0.902      0.946      0.772\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      2.57G     0.7864      1.111      1.129          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.8it/s 4.9s\n",
            "                   all        271        269       0.92      0.915      0.969      0.795\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      2.59G     0.7921       1.03      1.128          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.1it/s 4.2s\n",
            "                   all        271        269       0.78      0.813      0.914      0.746\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      2.61G     0.7413     0.9273      1.102          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:34\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.2it/s 4.0s\n",
            "                   all        271        269      0.956      0.972      0.985      0.841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      2.62G     0.7308     0.8095      1.087          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:30\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.8s\n",
            "                   all        271        269      0.938      0.955      0.974      0.824\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      2.64G     0.7437      0.777      1.101          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.8s\n",
            "                   all        271        269       0.94      0.961      0.983      0.837\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      2.66G     0.7282     0.7324       1.09          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 3.9s\n",
            "                   all        271        269      0.787      0.775       0.91      0.754\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      2.68G     0.7109     0.7157      1.075         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.8s\n",
            "                   all        271        269      0.888      0.911       0.95      0.813\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50       2.7G      0.696     0.6934      1.076          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.2it/s 4.0s\n",
            "                   all        271        269      0.823      0.864      0.942      0.792\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50      2.71G     0.7052     0.6801      1.085          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.8s\n",
            "                   all        271        269       0.95      0.967      0.987      0.853\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      2.73G     0.6875     0.6284       1.07          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:30\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 4.0s\n",
            "                   all        271        269      0.969      0.971      0.985      0.857\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      2.75G     0.6815     0.6231      1.068          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.8s\n",
            "                   all        271        269      0.905      0.944      0.936      0.817\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50      2.76G     0.6592     0.5994      1.056          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.8it/s 5.1s\n",
            "                   all        271        269      0.982      0.966       0.99      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      2.78G     0.6568     0.5608      1.052          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:25\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.8it/s 5.0s\n",
            "                   all        271        269      0.981      0.976      0.991      0.868\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50       2.8G     0.6471     0.5543      1.047          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.2it/s 4.1s\n",
            "                   all        271        269      0.973      0.982       0.99       0.87\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      2.81G     0.6554     0.5395      1.052          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.8it/s 5.1s\n",
            "                   all        271        269      0.966      0.994       0.99      0.864\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      2.83G      0.639     0.5158      1.051          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.6it/s 3.5s\n",
            "                   all        271        269      0.981      0.996       0.99      0.858\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      2.85G     0.6364     0.4927      1.041          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.7s\n",
            "                   all        271        269      0.987      0.999      0.993       0.87\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      2.87G     0.6243     0.4654      1.032         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:30\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 3.9s\n",
            "                   all        271        269      0.988      0.997      0.992      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      2.88G     0.6318     0.4866      1.038          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 4.0s\n",
            "                   all        271        269      0.983      0.995      0.992      0.873\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50       2.9G     0.6302     0.4985      1.042          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.8it/s 4.9s\n",
            "                   all        271        269      0.971       0.98      0.992      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      2.92G     0.6092     0.4551      1.024         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:34\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 3.9s\n",
            "                   all        271        269      0.971      0.989      0.992      0.871\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      2.93G     0.5951     0.4684      1.021          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:25\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 4.0s\n",
            "                   all        271        269      0.986      0.991      0.994      0.867\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50      2.95G     0.6025     0.4583       1.03          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.2it/s 4.1s\n",
            "                   all        271        269      0.988      0.995      0.993      0.883\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      2.97G     0.5954     0.4369      1.017          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.8it/s 5.0s\n",
            "                   all        271        269      0.991      0.999      0.993       0.89\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50      2.99G     0.5907     0.4453      1.015          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 3.9s\n",
            "                   all        271        269      0.986      0.998       0.99      0.882\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50         3G     0.5872     0.4203      1.023          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.8s\n",
            "                   all        271        269      0.985      0.995      0.994      0.894\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50      3.02G     0.5745     0.4071      1.007          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 3.9s\n",
            "                   all        271        269      0.987          1      0.991      0.893\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50      3.04G     0.5842       0.41      1.018          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.8s\n",
            "                   all        271        269      0.988      0.995       0.99      0.889\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50      3.05G     0.5626     0.3918      1.006          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.6it/s 3.5s\n",
            "                   all        271        269       0.99      0.995       0.99      0.893\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50      3.07G     0.5466     0.4014     0.9977          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.8it/s 4.9s\n",
            "                   all        271        269       0.99          1       0.99      0.896\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50      3.09G     0.5552     0.3745      1.005          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:34\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 4.0s\n",
            "                   all        271        269       0.99          1      0.991      0.894\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50       3.1G     0.5569     0.3728      0.998          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 4.0s\n",
            "                   all        271        269      0.987      0.998       0.99      0.896\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50      3.12G     0.5422     0.3754      1.003          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.7s\n",
            "                   all        271        269      0.989          1       0.99      0.894\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50      3.14G     0.5452     0.3709     0.9949         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:30\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 3.9s\n",
            "                   all        271        269      0.989          1      0.991       0.89\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50      3.15G     0.5475     0.3648      1.008          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.0it/s 4.4s\n",
            "                   all        271        269      0.988          1      0.992      0.899\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50      3.17G     0.5357     0.3704     0.9941          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 4.0s\n",
            "                   all        271        269      0.991      0.996      0.989        0.9\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50      3.19G     0.4282     0.3146     0.9318          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.6it/s 3.4s\n",
            "                   all        271        269      0.987      0.997      0.991      0.906\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50      3.21G     0.4303     0.3103     0.9439          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.4it/s 3.8s\n",
            "                   all        271        269      0.982          1      0.991      0.895\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50      3.22G     0.4242     0.3005     0.9256          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.6it/s 3.4s\n",
            "                   all        271        269      0.985          1      0.992      0.903\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50      3.24G     0.4116     0.2753     0.9223          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.3s/it 1:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.2it/s 4.1s\n",
            "                   all        271        269       0.99          1      0.991      0.908\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50      3.26G     0.4015     0.2745     0.9184          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.1s/it 1:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.8it/s 5.0s\n",
            "                   all        271        269      0.991          1      0.992       0.91\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50      3.28G     0.3896     0.2652     0.9029          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.4it/s 3.7s\n",
            "                   all        271        269      0.988      0.997      0.992      0.908\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50      3.29G     0.3775     0.2509     0.9032          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.0it/s 4.6s\n",
            "                   all        271        269      0.987          1      0.992      0.916\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50      3.31G     0.3788     0.2479     0.9028          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.7s\n",
            "                   all        271        269      0.991          1      0.991      0.908\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50      3.33G     0.3699     0.2472     0.8998          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.4it/s 3.7s\n",
            "                   all        271        269      0.991          1       0.99      0.915\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50      3.34G     0.3664     0.2539     0.8949          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 72/72 1.2s/it 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.5it/s 3.7s\n",
            "                   all        271        269      0.991          1       0.99      0.913\n",
            "\n",
            "50 epochs completed in 1.324 hours.\n",
            "Optimizer stripped from /content/runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.4.9 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 73 layers, 3,007,013 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.1s/it 19.0s\n",
            "                   all        271        269      0.987          1      0.992      0.915\n",
            "                  100k         51         51      0.977          1      0.982      0.911\n",
            "                   10k         52         52      0.979          1      0.993      0.958\n",
            "                    1k         40         40      0.978          1      0.995      0.881\n",
            "                   20k         52         52      0.998          1      0.995       0.86\n",
            "                    2k         33         33      0.995          1      0.995      0.946\n",
            "                    5k         41         41      0.996          1      0.995      0.934\n",
            "Speed: 0.2ms preprocess, 2.3ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Train the model with 2 GPUs\n",
        "results = model.train(data='Uang-Rupiah-2/data.yaml', epochs=50, imgsz=640, device=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5bf496c-65c0-4bc8-b076-e626ad5d87cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5bf496c-65c0-4bc8-b076-e626ad5d87cf",
        "outputId": "d6c7fd4c-0a78-4dae-8203-64a9dfc188dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.4.9 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 73 layers, 3,007,013 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5002.4Â±1292.9 MB/s, size: 932.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Uang-Rupiah-2/valid/labels.cache... 271 images, 2 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 271/271 87.4Mit/s 0.0s\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 10, len(boxes) = 269. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 17/17 1.1s/it 18.6s\n",
            "                   all        271        269      0.987          1      0.993      0.915\n",
            "                  100k         51         51      0.977          1      0.982      0.909\n",
            "                   10k         52         52      0.979          1      0.993      0.963\n",
            "                    1k         40         40      0.979          1      0.995      0.881\n",
            "                   20k         52         52      0.998          1      0.995      0.863\n",
            "                    2k         33         33      0.995          1      0.995       0.94\n",
            "                    5k         41         41      0.996          1      0.995      0.934\n",
            "Speed: 2.1ms preprocess, 5.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([     0.9093,     0.96324,     0.88076,     0.86308,     0.94004,       0.915,     0.93361])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Validate model\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('runs/detect/train/weights/best.pt')  # load a custom model\n",
        "\n",
        "# Validate the model\n",
        "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
        "metrics.box.map    # map50-95\n",
        "metrics.box.map50  # map50\n",
        "metrics.box.map75  # map75\n",
        "metrics.box.maps   # a list contains map50-95 of each category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28af2e54-9d78-4da5-8fa7-137344fcfd3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28af2e54-9d78-4da5-8fa7-137344fcfd3f",
        "outputId": "323061e4-63aa-447f-cd8e-03a862ecf2cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/image2.jpeg: 640x480 1 50k, 7.1ms\n",
            "Speed: 2.4ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1m/content/runs/detect/predict2\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: '100k', 1: '10k', 2: '1k', 3: '20k', 4: '2k', 5: '50k', 6: '5k'}\n",
              " obb: None\n",
              " orig_img: array([[[  5,   4,   0],\n",
              "         [  3,   2,   0],\n",
              "         [ 11,   9,   9],\n",
              "         ...,\n",
              "         [ 58,  60,  68],\n",
              "         [ 59,  62,  67],\n",
              "         [ 60,  63,  68]],\n",
              " \n",
              "        [[  6,   5,   1],\n",
              "         [  2,   1,   0],\n",
              "         [  3,   1,   1],\n",
              "         ...,\n",
              "         [ 67,  69,  77],\n",
              "         [ 67,  70,  75],\n",
              "         [ 67,  70,  75]],\n",
              " \n",
              "        [[  8,   7,   3],\n",
              "         [  2,   1,   0],\n",
              "         [  2,   0,   0],\n",
              "         ...,\n",
              "         [ 75,  77,  85],\n",
              "         [ 74,  77,  82],\n",
              "         [ 74,  77,  82]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 85,  92, 112],\n",
              "         [ 88,  95, 115],\n",
              "         [ 88,  97, 117],\n",
              "         ...,\n",
              "         [ 29,  21,  28],\n",
              "         [ 28,  21,  26],\n",
              "         [ 26,  19,  24]],\n",
              " \n",
              "        [[ 84,  91, 111],\n",
              "         [ 88,  95, 115],\n",
              "         [ 91,  98, 118],\n",
              "         ...,\n",
              "         [ 27,  20,  25],\n",
              "         [ 24,  17,  22],\n",
              "         [ 21,  14,  19]],\n",
              " \n",
              "        [[ 84,  91, 111],\n",
              "         [ 88,  95, 115],\n",
              "         [ 91,  98, 118],\n",
              "         ...,\n",
              "         [ 23,  16,  21],\n",
              "         [ 19,  12,  17],\n",
              "         [ 16,   9,  14]]], dtype=uint8)\n",
              " orig_shape: (1600, 1200)\n",
              " path: '/content/image2.jpeg'\n",
              " probs: None\n",
              " save_dir: '/content/runs/detect/predict2'\n",
              " speed: {'preprocess': 2.4102550005409284, 'inference': 7.076001000314136, 'postprocess': 1.4311329996417044}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#  Prediction using trained model\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pretrained YOLOv8n model\n",
        "model = YOLO('runs/detect/train/weights/best.pt')\n",
        "\n",
        "# Run inference\n",
        "model.predict('image2.jpeg', save=True, imgsz=640, conf=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f3d815e-d7ad-4f2d-b540-b3039f1230e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2f3d815e-d7ad-4f2d-b540-b3039f1230e1",
        "outputId": "d517ca28-6f7d-469d-8bef-0f9b14a91113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.4.9 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "ğŸ’¡ ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
            "Model summary (fused): 73 layers, 3,007,013 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/train/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 11, 8400) (5.9 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'ai-edge-litert>=1.2.0', 'onnx>=1.12.0,<2.0.0', 'onnx2tf>=1.26.3,<1.29.0', 'onnxslim>=0.1.71', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "Using Python 3.12.12 environment at: /usr\n",
            "Resolved 20 packages in 1.81s\n",
            "Prepared 11 packages in 5.19s\n",
            "Installed 11 packages in 399ms\n",
            " + ai-edge-litert==2.1.2\n",
            " + backports-strenum==1.3.1\n",
            " + colorama==0.4.6\n",
            " + coloredlogs==15.0.1\n",
            " + humanfriendly==10.0\n",
            " + onnx==1.20.1\n",
            " + onnx-graphsurgeon==0.5.8\n",
            " + onnx2tf==1.28.8\n",
            " + onnxruntime-gpu==1.23.2\n",
            " + onnxslim==0.1.82\n",
            " + sng4onnx==1.0.5\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 8.1s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 22...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exporting to ONNX opset version 22 is not supported. by 'torch.onnx.export()'. The highest opset version supported is 20. To use a newer opset version, consider 'torch.onnx.export(..., dynamo=True)'. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.82...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.3s, saved as 'runs/detect/train/weights/best.onnx' (11.8 MB)\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip': 100% â”â”â”â”â”â”â”â”â”â”â”â” 1.1MB 37.9MB/s 0.0s\n",
            "\u001b[KUnzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /content/calibration_image_sample_data_20x128x128x3_float32.npy...: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 52.0files/s 0.0s\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.8...\n",
            "Saved artifact at 'runs/detect/train/weights/best_saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 11, 8400), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  133295360553808: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  133295360552272: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n",
            "  133295360553040: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  133295359411216: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  133295360553616: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
            "  133295359410256: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  133295359411408: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  133295359411600: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  133295359412560: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295359412176: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295359414480: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
            "  133295359415056: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  133295359411792: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
            "  133295359410640: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  133295359413136: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295359412752: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133298838992080: TensorSpec(shape=(1, 1, 48, 32), dtype=tf.float32, name=None)\n",
            "  133295360548624: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  133295360545744: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  133295360555344: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  133295360545360: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295360547856: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295360548048: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295399141456: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295399144336: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295360547472: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  133295360547088: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  133295360548432: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  133295360544784: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  133295400599376: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  133295400598224: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  133295399143952: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  133295400598032: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  133295360548240: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295360546704: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295400598608: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  133295359415824: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295359412944: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  133295359414096: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
            "  133295359415440: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  133295359413904: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  133295359416016: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  133295359416400: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295359415632: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295359418128: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295359418320: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295359416208: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295359415248: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295359417552: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295359418512: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295359417168: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295359418896: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295359416592: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295359414672: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295359419280: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  133295359418704: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  133295359419472: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  133295359417744: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
            "  133295359419088: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  133295359419856: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  133295359420048: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  133295359420624: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295359420432: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295359422544: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  133295359422736: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  133295359420240: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  133295359419664: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  133295359420816: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295359421008: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295359422928: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  133295359421584: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  133295359421968: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  133295359423312: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  133295359423504: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  133295359423696: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  133295359424080: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
            "  133295359424272: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  133295359424656: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295359423888: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295359426000: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295359426384: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295359424464: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295359422160: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295359425424: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295359423120: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295359425232: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  133295359425616: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  133295359425808: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
            "  133295358624016: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358624784: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295358624592: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295358626704: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  133295358626896: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  133295358624400: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  133295358624208: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  133295358624976: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295358625168: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295358627280: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
            "  133295358627088: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358627472: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  133295358626128: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295358625744: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358629392: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  133295358628816: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  133295358631504: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295358630736: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295358632656: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295358633232: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358631120: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295358630352: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358633040: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295358631312: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295358633424: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  133295358632848: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  133295358633808: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  133295358630928: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  133295358632272: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  133295358635536: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  133295358634768: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  133295358638224: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295358634576: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295358638608: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  133295358638800: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  133295358636496: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  133295358637648: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  133295358638032: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295358636880: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  133295358639184: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  133295358638992: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  133295358637840: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  133295358631696: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  133295358627856: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295358639376: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358634192: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358627664: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358639760: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295358634000: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295358628048: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295358639952: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358633616: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358628432: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295371583952: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295358635728: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295358629776: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295371584336: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358635344: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358629200: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358639568: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  133295358634384: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  133295358628240: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295358637456: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358630544: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358626320: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358636688: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295358634960: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295358629008: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  133295371583568: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358635152: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295358628624: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  133295371585872: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
            "  133295371584528: TensorSpec(shape=(1, 1, 64, 7), dtype=tf.float32, name=None)\n",
            "  133295358636112: TensorSpec(shape=(1, 1, 64, 7), dtype=tf.float32, name=None)\n",
            "  133295358630160: TensorSpec(shape=(1, 1, 64, 7), dtype=tf.float32, name=None)\n",
            "  133295371584144: TensorSpec(shape=(7,), dtype=tf.float32, name=None)\n",
            "  133295358635920: TensorSpec(shape=(7,), dtype=tf.float32, name=None)\n",
            "  133295358629584: TensorSpec(shape=(7,), dtype=tf.float32, name=None)\n",
            "  133295371586064: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  133295371586256: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  133295371585296: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  133295371587216: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  133295371586640: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  133295371586832: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 31.3s, saved as 'runs/detect/train/weights/best_saved_model' (29.5 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.19.0...\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success âœ… 0.0s, saved as 'runs/detect/train/weights/best_saved_model/best_float32.tflite' (11.7 MB)\n",
            "\n",
            "Export complete (31.8s)\n",
            "Results saved to \u001b[1m/content/runs/detect/train/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=runs/detect/train/weights/best_saved_model/best_float32.tflite imgsz=640 \n",
            "Validate:        yolo val task=detect model=runs/detect/train/weights/best_saved_model/best_float32.tflite imgsz=640 data=Uang-Rupiah-2/data.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'runs/detect/train/weights/best_saved_model/best_float32.tflite'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#  Export model to tflite\n",
        "\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('runs/detect/train/weights/best.pt')  # load a custom trained model\n",
        "\n",
        "# Export the model\n",
        "model.export(format='tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3aae33b-b14a-43f6-861f-3e0f2d21407f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "b3aae33b-b14a-43f6-861f-3e0f2d21407f",
        "outputId": "0c98e85c-4462-45d7-df7b-9bcbb2c161af"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ultralytics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3065394280.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#  Prediction using trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load a pretrained YOLOv8n model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Prediction using custom tflite model\n",
        "\n",
        "#  Prediction using trained model\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pretrained YOLOv8n model\n",
        "model = YOLO('/content/runs/detect/train/weights/best.pt')\n",
        "\n",
        "# Run inference\n",
        "model.predict('image.jpeg', save=True, imgsz=640, conf=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Nama folder hasil training YOLOv8 secara default adalah 'runs'\n",
        "folder_to_zip = 'runs'\n",
        "output_filename = 'hasil_training_uang.zip'\n",
        "\n",
        "# Proses mengompres folder\n",
        "print(f\"Sedang mengompres folder {folder_to_zip}...\")\n",
        "shutil.make_archive(output_filename.replace('.zip', ''), 'zip', folder_to_zip)\n",
        "\n",
        "print(f\"Selesai! File {output_filename} siap diunduh.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKLyaSQqQpJt",
        "outputId": "fc213dbd-b3cb-4efa-f0e3-3f464f443478"
      },
      "id": "PKLyaSQqQpJt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sedang mengompres folder runs...\n",
            "Selesai! File hasil_training_uang.zip siap diunduh.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}